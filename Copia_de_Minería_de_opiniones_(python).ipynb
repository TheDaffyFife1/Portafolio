{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w_ETTd3AsGO",
        "outputId": "41aba227-2964-4434-bb1b-9c9d288e4be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0hVxI4o_gYu"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eixY3nZ-7lON"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "El objetivo de la minería de opiniones es el de asociar, de forma automática, un *sentimiento* con algún comentario escrito. La minería de opiniones es una de las estrategias más utilizadas en la actualidad para extraer información de diversas fuentes dado el auge que tiene la comunicación escrita a través de la web: **correos electrónicos, comentarios en sitios web o redes sociales, blogs, discusiones en foros, etc.**\n",
        "\n",
        "La siguiente gráfica muestra los resultados de una encuesta aplicada a diferentes asistentes (representantes de la industria y de la academia) a la conferencia del Journal of Data Analysis Techniques (2014), en la cual se solicitó a los participantes identificar las fuentes de datos textuales que utilizan con mayor frecuencia:\n",
        "\n",
        "<img src=\"fuentes.png\" width=400/>\n",
        "\n",
        "La imagen corresponde al libro de *Essentials of Business Analytics* de Pochiraju.\n",
        "\n",
        "Podemos plantear de forma progresiva el objetivo de la minería de opiniones, limitando los sentimientos que se pueden asociar a un comentario, reduciéndolos por ejemplo a tres categorías:\n",
        "\n",
        "$$\\{\\text{negativo}, \\text{neutro}, \\text{positivo}\\}$$\n",
        "\n",
        "Con estas etiquetas, buscamos idenificar la **polaridad** de un comentario. Aún así, lograr el objetivo de la minería de opiniones puede ser un gran desafío. Considera el siguiente comentario:\n",
        "\n",
        "        \"Compré un IPhone hace algunos días. Resultó ser un excelente teléfono. La pantalla táctil es fantástica. El sonido es muy claro. Sin embargo, mi madre se molestó porque lo compré sin pedirle permiso. Ella piensa que el teléfono es muy caro y me ha pedido que lo regrese a la tienda.\"\n",
        "        \n",
        "**¿Qué polaridad le asignarías?**\n",
        "\n",
        "## Planteamiento del problema\n",
        "\n",
        "Para ganar claridad, podemos plantear el problema de manera formal. Dado un fragmento de texto (comentario) buscamos identificar los siguientes elementos:\n",
        "\n",
        "$$(e, a, oo, s, t)$$\n",
        "\n",
        "* $e$: es la entidad de la cual se opina (por ejemplo del IPhone).\n",
        "* $a$: atributo de la entidad (pantalla táctil o sonido).\n",
        "* $oo$: orientación de la opinión (positiva, negativa o neutra).\n",
        "* $s$: sujeto que emite la opinión (el comprador del teléfono o su mamá).\n",
        "* $t$: momento en el que se emite la opinión.\n",
        "\n",
        "\n",
        "En este curso exploraremos dos estrategias para abordar el problema de la minería de opiniones. La primera de ellas plantea el problema como uno de **aprendizaje automático** y la segunda se basa en el uso de **lexicones**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2G6bAdG7lOS"
      },
      "source": [
        "# Minería de opiniones con aprendizaje supervisado\n",
        "\n",
        "Para poder aplicar esta estrategia es necesario disponer de un conjunto de comentarios para los cuales se ha identificado la polaridad. En las aplicaciones reales, puede ser necesario realizar la identificación de la polaridad manualmente, lo cual representa una desventaja importante debido a que para obtener resultados confiables puede ser necesario construir un **conjunto de entrenamiento** con decenas de miles de observaciones.  \n",
        "\n",
        "Esta estrategia se basa en la representación de cada comentario como un vector de características, específicamente a través de la construcción de la **matriz TF (frecuencia de de término) o de la TF-IDF** (frecuencia de término y frecuencia inversa de documento). Una vez que se ha construido esta matriz, puede construirse un modelo utilizando alguna técnica de clasificación; **naive Bayes** y las **máquinas de soporte vectorial** son dos de las más utilizadas.\n",
        "\n",
        "En las siguientes celdas se muestra un ejemplo de la aplicación de las máquinas de soporte vectorial sobre un conjunto de comentarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1u5odFQ7lOT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "D9ncc5BW7lOV",
        "outputId": "5def7d96-aa4e-40b2-f2f2-7dab64a778f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-88d219f848b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amazon_baby.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 1973, saw 7\n"
          ]
        }
      ],
      "source": [
        "comments = pd.read_csv(\"amazon_baby.csv\")\n",
        "comments.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq0X6PYP7lOW"
      },
      "source": [
        "Considerando la calificación que el usuario otorgó en cada comentario (rating) podemos identificar la polaridad de cada comentario, de manera que etiquetamos como *positivos* a los que tienen una calificación mayor a 3 y *negativos* los que tienen una calificación menor a 3. Los calificados con 3 pueden considerarse *neutrales*, pero para este ejemplo se ignorarán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "g9vyjyaO7lOW",
        "outputId": "ff41e97e-984c-44d0-dfa9-ab61db34a383"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7b6ebfc0a16c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"polaridad\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
          ]
        }
      ],
      "source": [
        "df = comments.loc[comments[\"rating\"] != 3]\n",
        "df[\"polaridad\"] = df['rating'].apply(lambda x: 1 if x > 3 else -1)\n",
        "df = df.dropna()\n",
        "df = df.sample(n = 10000)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbV1aGrU7lOX"
      },
      "source": [
        "La tabla de datos original contiene poco menos de 200 mil comentarios, pero para esta aplicación consideraremos una muestra de 10 mil.\n",
        "\n",
        "Considera que la mayoría de los comentarios tienen una polaridad positiva (84%):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrEptFg97lOY",
        "outputId": "13d4d5dc-8154-44ec-a238-d8c2978107d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8365"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.loc[df[\"polaridad\"] > 0])/len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4TU3A_s7lOZ"
      },
      "source": [
        "## Preproceso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTosyUK97lOZ"
      },
      "source": [
        "Vectorizamos los comentarios y separamos conjuntos de entrenamiento y de prueba. Además limitamos el total de términos a los 100 más frecuentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpwWtkMm7lOa"
      },
      "outputs": [],
      "source": [
        "corpus = df[\"review\"]\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=100)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "y = df[\"polaridad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IMB-WUj7lOa",
        "outputId": "eb176575-785e-4802-81d2-a300229e4a86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 100)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYXH15tX7lOa"
      },
      "outputs": [],
      "source": [
        "# 70% de las observaciones se usan para construir el modelo\n",
        "# el restante 30% para probar\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4whHkl1U7lOb"
      },
      "source": [
        "Construimos un modelo basándonos en una máquina de soporte vectorial para clasificar los comentarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZCex4qlV7lOb",
        "outputId": "0193f800-ce55-4691-810b-b1812bd636f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best estimator found by grid search:\n",
            "SVC(C=10, class_weight='balanced', gamma=0.0001)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {'C': [1, 10, 1e2, 1e3], 'gamma': [0.01, 0.001, 0.0001]}\n",
        "\n",
        "clf = GridSearchCV(\n",
        "    SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_train, y_train)\n",
        "print(\"Best estimator found by grid search:\")\n",
        "print(clf.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2tOadRN7lOb",
        "outputId": "eeaa8151-aa27-4ea7-91af-eb23bacdc0e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7346666666666667"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_predicted = clf.predict(X_test)\n",
        "\n",
        "#exactitud\n",
        "sum(y_predicted == y_test)/y_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLF_6Z_J7lOc",
        "outputId": "9f960939-6941-4ac3-b703-e112d81276b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reporte del clasificador:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.79      0.49       477\n",
            "           1       0.95      0.72      0.82      2523\n",
            "\n",
            "    accuracy                           0.73      3000\n",
            "   macro avg       0.65      0.76      0.65      3000\n",
            "weighted avg       0.85      0.73      0.77      3000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#otras métricas\n",
        "from sklearn import metrics\n",
        "\n",
        "print(f\"Reporte del clasificador:\\n\"\n",
        "      f\"{metrics.classification_report(y_test, y_predicted)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL7APoo97lOc"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "Otra técnica que se aplica con mucho éxito en la minería de opiniones (y en la clasificación de documentos en general) es la de Naive Bayes.\n",
        "\n",
        "Suponemos que observamos un vector de características, $X$, (vector de frecuencia de términos por ejemplo), nos interesamos en evaluar la probabilidad condicionada $$P(Y \\;|\\; X)$$ para cada una de las clases, en nuestro ejemplo, deberíamos evaluar $P(Y =1\\;|\\; X)$ y $P(Y = -1 \\;|\\; X)$.\n",
        "\n",
        "Una vez que evaluamos las probabilidades, para clasificar a un comentario, solamente debemos comparar $P(Y =1\\;|\\; X)$ y $P(Y = -1 \\;|\\; X)$.\n",
        "\n",
        "La evaluación se realiza a través de la regla de Bayes:\n",
        "\n",
        "$$P(Y \\; | \\; X) = \\frac{P(X \\; | \\; Y)P(Y)}{P(X)}$$\n",
        "\n",
        "Más aún, en la técnica de Naive Bayes, suponemos que las características son independientes una vez que se conoce la clase, esto es, podemos evaluar la **verosimilitud** son la siguiente expresión\n",
        "\n",
        "$$P(X \\;|\\; Y) = P(x_1, x_2, \\ldots, x_d \\;|\\;Y) = \\prod_{i=1}^d P(x_i\\;| \\; Y)$$\n",
        "\n",
        "Evaluar estas probabilidades es muy sencillo, solamente debemos contar cuántas veces aparece el término $x_i$ en los comentarios asociados a cada clase.\n",
        "\n",
        "### Ejemplo\n",
        "\n",
        "Por ejemplo, supongamos que utilizamos los siguientes comentarios acerca de un artículo para la aplicación del método de Naive Bayes:\n",
        "\n",
        "1. \"La calidad es excelente\" ($Y=1$)\n",
        "2. \"El artículo es muy bueno en general, pero el diseño sobresale, es excelente\" ($Y=1$)\n",
        "3. \"No es malo, es pésimo\" ($Y=-1$)\n",
        "4. \"No me satisface\" ($Y=-1$)\n",
        "5. \"El artículo es muy malo\" ($Y=-1$)\n",
        "\n",
        "\n",
        "Tenemos las siguientes probabilidades:\n",
        "\n",
        "1. $P(Y=1) = \\frac{2}{5}$\n",
        "2. $P(Y=-1) = \\frac{3}{5}$\n",
        "\n",
        "Supongamos que los términos que componen el vocabulario son: $$\\{\\text{excelente}, \\text{bueno}, \\text{pésimo}, \\text{satisface}, \\text{malo}\\}$$\n",
        "\n",
        "Entonces:\n",
        "\n",
        "1. $P(\\text{bueno} \\;|\\; Y = 1) = \\frac{1}{2}$\n",
        "2. $P(\\text{excelente} \\;|\\; Y = 1) = 1$\n",
        "3. $P(\\text{pésimo} \\;|\\; Y = -1) = \\frac{1}{3}$\n",
        "4. $P(\\text{malo} \\;|\\; Y = -1) = \\frac{2}{3}$\n",
        "\n",
        "Podemos evaluar las probabilidades $P(Y=1\\;|\\;X)$ y $P(Y=-1\\;|\\;X)$ para un nuevo comentario, como, \"Me parece excelente\":\n",
        "\n",
        "\\begin{align}\n",
        "    P(Y=1\\;&|\\;\\text{excelente}=1, \\text{bueno}=0, \\text{pésimo}=0, \\text{satisface}=0, \\text{malo}=0)\\\\ &= P(\\text{excelente}\\;|\\; Y=1)\\times P(\\sim \\text{bueno}\\;|\\; Y=1)\\times \\cdots\\\\ &\\times P(\\sim \\text{malo}\\;|\\; Y=1)\\times P(Y=1)/k\\\\\n",
        "    &=1\\times\\frac{1}{2}\\times 1 \\times 1 \\times 1 \\times \\frac{2}{5} /k\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "## Suavizado de Laplace\n",
        "\n",
        "Cabe señalar que, de aplicarse el método de Naive Bayes tal como está definido, es muy probable que varias probabilidades tomen el valor de cero; por ejemplo, si el comentario fuera **El producto me satisface, es excelente**, entonces $P(Y = 1 \\;|\\; X) = 0$ dado que $P(\\text{satisface} \\;|\\; Y = 1) = 0$ (la palabra *satisface* no aparece en los comentarios con polaridad positiva):\n",
        "\n",
        "$$P(Y = 1 \\;|\\; X) = 1\\times \\frac{1}{2} \\times 1 \\times \\color{red}{0} \\times 1 \\times \\frac{2}{5}/k = 0$$\n",
        "\n",
        "Para evitar este problema, modificamos la evaluación de las probabilidades usando el criterio de suavizado de Laplace:\n",
        "\n",
        "$$P(X_i \\; | \\; Y=y_j) = \\frac{(\\text{# documentos en de la clase } y_j \\text{ en donde aparezca } X_i)+\\alpha}{N_{y_j}+\\alpha d}$$\n",
        "\n",
        "Observa que con esta condición, si $\\alpha=0.01$:\n",
        "\n",
        "$$P(\\text{satisface} \\; | \\; Y=1) = \\frac{0+\\alpha}{2+\\alpha\\times 5} = 0.0049$$\n",
        "\n",
        "De esta forma, se tendría:\n",
        "\n",
        "$$P(Y = 1 \\;|\\; X) = 1\\times \\frac{1}{2} \\times 1 \\times \\color{red}{0.0048} \\times 1 \\times \\frac{2}{5}/k$$\n",
        "\n",
        "Como ejercicio, evalúa $P(Y=-1 \\; | \\; X)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un3MbMr47lOd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}